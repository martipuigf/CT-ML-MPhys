# -*- coding: utf-8 -*-
"""U_Net_4_superresolution_in_EM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bTbbAyUQHMTCQ7nR3nqjWMnRAXa3K5-j

Training School # 4 of NEUBIAS COST Action
February 29th-March 3rd, 2020, Bordeaux

# Deep Learning example: U-Net for super-resolution

---
## Introduction
This is a notebook that shows how to design and train a U-Net-like network for super-resolution on Electron Miscroscopy (EM) images. The aim is to train the network using low resolution versions of the images as input, and the high resolution versions as output.

<figure>
<center>
<img src="https://drive.google.com/uc?id=1KUCwas63FD6AfiKOetiGjLRR6oldNkKC" width="450">
</figure>



## Data
The image data used in the notebook was produced by [Lichtman Lab at Harvard University](https://lichtmanlab.fas.harvard.edu/) (Daniel R. Berger, Richard Schalek, Narayanan "Bobby" Kasthuri, Juan-Carlos Tapia, Kenneth Hayworth, Jeff W. Lichtman). Their corresponding biological findings were published in [Cell (2015)](https://www.ncbi.nlm.nih.gov/pubmed/26232230).
The training and test data sets are both 3D stacks of 100 sections from a serial section Scanning Electron Microscopy (ssSEM) data set of mouse cortex. The microcube measures 6 x 6 x 3 microns approx., with a resolution of 6 x 6 x 30 nm/voxel. For simplicity, in this notebook we will only use 10 sections of the test set.

## Getting started
First, we make sure we are using Tensorflow version compatible with DeepImageJ (<= 1.13).
"""

# Commented out IPython magic to ensure Python compatibility.
# Use Tensorflow and Keras versions compatible with DeepImageJ
#%pip install tensorflow-gpu==2.5.0
#%pip install keras==2.2.4

"""Then, we load our Google Drive as a local folder so we can access the image files.

(Notice we expect you to have already this notebook under your `Colab Notebooks` in a folder called `U-Net-Super-resolution`. Inside that folder you should add the `train` and `test` image folders.)
"""

"""Now we should be able to read the list of **100 training images**."""

def classic_crappify(img):
    img = filters.gaussian(img, sigma=3) + 1e-6
    
    return img

def create_patches( imgs, num_x_patches, num_y_patches ):
    ''' Create a list of images patches out of a list of images
    Args:
        imgs: list of input images
        num_x_patches: number of patches in the X axis
        num_y_patches: number of patches in the Y axis
        
    Returns:
        list of image patches
    '''
    original_size = imgs[0].shape
    patch_width = original_size[ 0 ] // num_x_patches
    patch_height = original_size[ 1 ] // num_y_patches
    
    patches = []
    for n in range( 0, len( imgs ) ):
        image = imgs[ n ]
        for i in range( 0, num_x_patches ):
            for j in range( 0, num_y_patches ):
                patches.append( image[ i * patch_width : (i+1) * patch_width,
                                      j * patch_height : (j+1) * patch_height ])#.astype(dtype='uint8') ) # All .astype comments can be removed for greater # of files (but ML is slower)
    return patches

import os
from skimage.util import img_as_ubyte
from skimage import io
from matplotlib import pyplot as plt
import tensorflow as tf
import numpy as np
from skimage import filters


train_path = 'C:/Users/HMXIF Remote/Harry/train_data/' # MAKE THIS INSTEAD OF 76 X 100 X 256 X 256 MAKE IT 7600 X 256 X 256
OUTPUT_DIR = "C:/Users/HMXIF Remote/Harry/ML_results_and_models/saved_model" # POSITION WHERE THE MODEL IS TO SAVED

train_filenames = [x for x in os.listdir( train_path ) if x.endswith(".tif")]

print( 'Images loaded: ' + str( len(train_filenames)) )
number_files = int(len(train_filenames))

# read training images
train_img = [ img_as_ubyte( io.imread( train_path + x ) ) for x in train_filenames ]

model = tf.keras.models.load_model('C:/Users/HMXIF Remote/Harry/ML_results_and_models/saved_model')
model.summary()

from keras.callbacks import EarlyStopping

numEpochs = 1 # i.e. number of times the training data set has had the chance to update the model parameters
earlystopper = EarlyStopping(patience=5, verbose=1, restore_best_weights=True)
total_files = 240
groups_to_learn = 20
files = 0

while files<total_files:
    
    model = tf.keras.models.load_model('C:/Users/HMXIF Remote/Harry/ML_results_and_models/saved_model')
    train_img_resized = []
    for scan in train_img[files:files+groups_to_learn]:
        for cross_section in scan[:]:
            train_img_resized.append(cross_section)

    crappified_patches = [classic_crappify(x) for x in train_img_resized]

    train_width = 256
    train_height = 256
    
    input_shape = ( train_width, train_height, 1 ) # 256x256x1
    X_train = [np.reshape(x, input_shape ) for x in crappified_patches] # Blurred images
    X_train = np.asarray(X_train)
    
    # training ground truth
    output_shape = ( train_width, train_height, 1 ) # 256x256x1
    Y_train = [x/255 for x in train_img_resized[:]] # normalize between 0 and 1
    Y_train = [np.reshape( x, output_shape ) for x in Y_train] # Clear images
    Y_train = np.asarray(Y_train)

    history = model.fit(X_train, Y_train, validation_split=0.1, batch_size = 6,
                        epochs=numEpochs, callbacks=[earlystopper])

    model.save(OUTPUT_DIR)
    files += groups_to_learn

"""We can now plot the loss and MAE curves for the training and validation sets."""

plt.figure(figsize=(14,5))

# summarize history for loss
plt.subplot(1, 2, 1)
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')

# summarize history for MAE
plt.subplot(1, 2, 2)
plt.plot(history.history['mean_absolute_error'])
plt.plot(history.history['val_mean_absolute_error'])
plt.title('model MAE')
plt.ylabel('MAE')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

"""## Check performance in the test set
Finally we can load some test images for testing.
"""

# Now we load some unseen images for testing
test_path = 'C:/Users/HMXIF Remote/Harry/test_data/'

test_filenames = [x for x in os.listdir( test_path ) if x.endswith(".tif")]



# train_img = [ img_as_ubyte( io.imread( train_path + x ) ) for x in train_filenames ]

# train_img_resized = []
# for scan in train_img[:]:
#     for cross_section in scan[:]:
#         train_img_resized.append(cross_section)

# train_img = train_img_resized

print( 'Available test images: ' + str( len(test_filenames)) )

# Read test images
test_img = [ img_as_ubyte( io.imread( test_path + x ) ) for x in test_filenames ]
test_img_resized = []

for scan in test_img[:]:
    for cross_section in scan[:]:
        test_img_resized.append(cross_section)
        
test_img = test_img_resized

# Create patches the same way as before
test_patches = create_patches( test_img, 1, 1 )

# Add noise
crappified_test_patches = [classic_crappify(x) for x in test_patches]

# Display corresponding first patch at low resolution
plt.figure(figsize=(10,5))
plt.subplot(1, 2, 1)
plt.imshow( crappified_test_patches[0], 'gray' )
plt.title( 'Test patch at low resolution' )
# Side by side with its "ground truth"
plt.subplot(1, 2, 2)
plt.imshow( test_patches[0], 'gray' )
plt.title( 'Ground truth' )

"""We can evaluate the network performance in test using both the MSE and MAE metrics."""

patch_shape = test_patches[0].shape
test_width = 256
test_height = 256
input_shape = ( test_width, test_height, 1 )

# Evaluate trained network on test images
X_test = [np.reshape(x, input_shape ) for x in crappified_test_patches]
X_test = np.asarray(X_test)
output_shape = ( test_width, test_height, 1 )

Y_test = [x/255 for x in test_patches] # normalize between 0 and 1
Y_test = [np.reshape( x, output_shape ) for x in Y_test]
Y_test = np.asarray(Y_test)

# Evaluate the model on the test data using `evaluate`
print('\n# Evaluate on test data')
results = model.evaluate(X_test, Y_test , batch_size=16)
print('test loss, test MAE:', results)

"""And also display some patches for qualitative evaluation."""

print('\n# Generate predictions for 3 samples')
predictions = model.predict(X_test[:,:,:,:])
print('predictions shape:', predictions.shape)

# Display corresponding first 3 patches
plt.figure(figsize=(15,15))
plt.subplot(3, 3, 1)
plt.imshow( crappified_test_patches[0], 'gray' )
plt.title( 'Test patch at low resolution' )
# Side by side with its "ground truth"
plt.subplot(3, 3, 2)
plt.imshow( test_patches[0], 'gray' )
plt.title( 'Ground truth' )
# and its prediction
plt.subplot(3, 3, 3)
plt.imshow( predictions[0,:,:,0], 'gray' )
plt.title( 'Prediction' )

plt.subplot(3, 3, 4)
plt.imshow( crappified_test_patches[1], 'gray' )
plt.title( 'Test patch at low resolution' )
# Side by side with its "ground truth"
plt.subplot(3, 3, 5)
plt.imshow( test_patches[1], 'gray' )
plt.title( 'Ground truth' )
# and its prediction
plt.subplot(3, 3, 6)
plt.imshow( predictions[1,:,:,0], 'gray' )
plt.title( 'Prediction' )

plt.subplot(3, 3, 7)
plt.imshow( crappified_test_patches[2], 'gray' )
plt.title( 'Test patch at low resolution' )
# Side by side with its "ground truth"
plt.subplot(3, 3, 8)
plt.imshow( test_patches[2], 'gray' )
plt.title( 'Ground truth' )
# and its prediction
plt.subplot(3, 3, 9)
plt.imshow( predictions[2,:,:,0], 'gray' )
plt.title( 'Prediction' )



# TO RE-OPEN AND TRAIN FURTHER THE MODEL

new_model = tf.keras.models.load_model(OUTPUT_DIR)


